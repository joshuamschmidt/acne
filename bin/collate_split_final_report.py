#!/usr/bin/env python
import argparse
import textwrap
import csv
import numpy as np
import os
import polars as pl

'''required and optional argument parser'''

parser = argparse.ArgumentParser(
    prog='collate_split_final_report',
    formatter_class=argparse.RawDescriptionHelpFormatter,
    description=textwrap.dedent('''\
    Collate Split Final report
    --------------------------------------------
    Generates a Combined signal intensity file from
    individual files generated by PENNCNV
    split_illumina_report.pl from an Illumina
    Studio final report

    If you want Chr and Position, you also need to provide
    a file for that...
    '''),
    add_help=False,
    epilog="Questions?\njoshmschmidt1@gmail.com\ngithub.com/joshuamschmidt")
parser._action_groups.pop()
required = parser.add_argument_group('required arguments')
optional = parser.add_argument_group('optional arguments')

# user args

required.add_argument(
    '--files',
    metavar='FS',
    type=str,
    nargs='+',
    help='files to collate'
)

required.add_argument(
    '--out',
    type=argparse.FileType('w'),
    dest='out_file',
    help='output file (or stdout if not set)'
)

optional.add_argument(
    '--name_map',
    type=str,
    dest='n_map',
    help='file listing oldname new name mapping',
    default=None
)

optional.add_argument(
    '--coordinates',
    type=str,
    dest='coord',
    help='file listing snp Chr, Pos, SNP name',
    default=None
)

# Add back help
optional.add_argument(
    '-h',
    '--help',
    action='help',
    default=argparse.SUPPRESS,
    help='show this help message and exit'
)


class MergedData():
    def __init__(self, files):
        self.files = files
        self.n_files = len(self.files)
        self.required = ['Name', 'B Allele Freq', 'Log R Ratio']
        self.snp_name_index = []
        self.__get_snp_names()
        self.n_snps = len(self.snp_name_index)
        self.data_array = np.empty([self.n_snps, self.n_files * 2],
                                   dtype=np.float64)
        self.sample_names = []

    def __get_snp_names(self):
        with open(self.files[0], 'rt', newline='') as f:
            dialect = csv.Sniffer().sniff(f.read(1024))
            f.seek(0)
            f_reader = csv.reader(f, dialect)
            for i, line in enumerate(f_reader):
                if i == 0:
                    assert('Name' in line)
                    name_idx = line.index('Name')
                else:
                    self.snp_name_index.append(line[name_idx])

    def fill_data_array(self):
        # for 0..k samples, fill 2n, 2n+1 (BAF then LRR)
        for i, file in enumerate(self.files):
            s = Sample(file, self.snp_name_index)
            b_i = i * 2
            l_i = b_i + 1
            self.sample_names.append(s.name)
            self.data_array[:, b_i] = s.data_array[:, 0]
            self.data_array[:, l_i] = s.data_array[:, 1]

    def rename_samples(self, name_file):
        nameKey = NameKey(name_file)
        for i, n in enumerate(self.sample_names):
            new_name = nameKey.names.get(n, None)
            if new_name is not None:
                self.sample_names[i] = new_name

    def write_merged(self, outfile):
        namesdf = pl.Series("Name", self.snp_name_index)
        data_cols = [[s+'.B Allele Freq', s+'.Log R Ratio'] for s in self.sample_names]
        data_cols = [c for tup in data_cols for c in tup]
        datadf = pl.from_numpy(self.data_array, schema = data_cols)
        datadf.insert_column(0, namesdf)
        datadf.write_csv(file = )


class Sample():
    def __init__(self, file, snp_name_index):
        self.file = file
        self.data_array = np.empty([len(snp_name_index), 2], dtype=np.float64)
        data = pl.read_csv(self.file, separator='\t', has_header=True)
        assert(data.get_column_index("Name") == 0)
        np.all(data.get_column("Name").to_numpy() == np.asarray(snp_name_index))
        data_col_ids = [c.split('.')[1] for c in list(data.columns)[1:]]
        s_names = [c.split('.')[0] for c in list(data.columns)[1:]]
        assert(np.size(np.unique(s_names)) == 1)
        self.name = np.unique(s_names)[0]
        idxs = [data_col_ids.index(c) + 1 for c in ['B Allele Freq', 'Log R Ratio']]
        assert(len(idxs) == 2)
        self.data_array[:, 0] = data.get_column(data.columns[idxs[0]]).to_numpy()
        self.data_array[:, 1] = data.get_column(data.columns[idxs[1]]).to_numpy()


class NameKey():
    def __init__(self, namefile):
        self.namefile = namefile
        self.names = {}
        self.get_names()

    def get_names(self):
        with open(self.namefile, 'rt', newline='') as m:
            dialect = csv.Sniffer().sniff(m.read(1024))
            m.seek(0)
            m_reader = csv.reader(m, dialect)
            for line in m_reader:
                self.names[line[0]] = line[1]


def main():
    args = parser.parse_args()
    if args.n_map is not None:
        names = NameKey(args.n_map)


if __name__ == '__main__':
    main()
